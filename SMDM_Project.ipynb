{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Run the application on the Bokeh server using the following command:\n",
    "bokeh serve --show SMDM_Project.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Importing all the  required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from bokeh.io import curdoc, output_file\n",
    "from bokeh.layouts import row, column, widgetbox\n",
    "from bokeh.models import ColumnDataSource\n",
    "from bokeh.models.widgets import Slider, TextInput, DataTable, TableColumn\n",
    "from bokeh.plotting import figure\n",
    "from bokeh.models.glyphs import Text\n",
    "from bokeh.models.tools import HoverTool\n",
    "from bokeh.models.annotations import LabelSet\n",
    "import bokeh.palettes\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from ipywidgets import widgets\n",
    "from IPython.display import display\n",
    "from IPython.display import clear_output\n",
    "\n",
    "from collections import Counter\n",
    "from datetime import datetime, date\n",
    "from numpy import pi\n",
    "import csv\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Module to split the words in the tweets and count the number of occurences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def word_counter(comments, review):\n",
    "  extracted_comments = \" \".join([c[0].lower() for c in comments if c[1] == review])\n",
    "  words = re.split(\"\\s+\", extracted_comments)\n",
    "  return Counter(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Module to count the number of elements in each class in the training data set, to calculate the prior probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def review_count(review,train_data):\n",
    "  return len([t for t in train_data if t[1] == review])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Module to perform the actual prediction by calculating the conoditional probability and then multiplying with the prior probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(review, counts_num, probability, classCount):\n",
    "  prediction = 1\n",
    "  review_count = Counter(re.split(\"\\s+\", review))\n",
    "  for word in review_count:\n",
    "    # Calculate the probability for each term for each class\n",
    "      prediction *=  review_count.get(word) * ((counts_num.get(word, 0) + 1) / (sum(counts_num.values()) + classCount))\n",
    "    # Multiply each class' probability with the apriori probability of that class, which is passed to the function, as 'probability'\n",
    "  return prediction * probability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Module to classify the tweets based on the probabilities obtained for each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict(review, counts_num, probability, classCount):\n",
    "  prediction = 1\n",
    "  review_count = Counter(re.split(\"\\s+\", review))\n",
    "  for word in review_count:\n",
    "    # Calculate the probability for each term for each class\n",
    "      prediction *=  review_count.get(word) * ((counts_num.get(word, 0) + 1) / (sum(counts_num.values()) + classCount))\n",
    "    # Multiply each class' probability with the apriori probability of that class, which is passed to the function, as 'probability'\n",
    "  return prediction * probability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Module to classify the tweets into classes based on the probabilities calculated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def decide(review, predict, negative_counts, negative_probability, negative_review_count, positive_counts, positive_probability, positive_review_count):\n",
    "    negative_prediction = predict(review, negative_counts, negative_probability, negative_review_count)\n",
    "    positive_prediction = predict(review, positive_counts, positive_probability, positive_review_count)\n",
    "    \n",
    "    # The class with the highest probability is assigned as the class of the tweet\n",
    "    if negative_prediction > positive_prediction:\n",
    "      return 'Negative'\n",
    "    return 'Positive'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Module to concatenate all the tweets to print in the output screen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def update_text(neg_comments,pos_comments):\n",
    "    datan.text = \"\"\n",
    "    datap.text = \"\"\n",
    "    for i in range(len(neg_comments)):\n",
    "        datan.text = datan.text + \"\\n\" + neg_comments[i] + \"\\n\"\n",
    "    for j in range(len(pos_comments)):\n",
    "        datap.text = datap.text + \"\\n\" + pos_comments[j] + \"\\n\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Module to perform Naive Bayes. This module calls other modules to calculate the probabilities and make the predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def naive_bayes(topic):\n",
    "    clear_output()\n",
    "    global p, dot, hover, hover1\n",
    "    \n",
    "    # Clearing the charts that were plotted for the previous tweet topic\n",
    "    \n",
    "    # Obtaining the chart components of the previous tweet topic\n",
    "    first_old = dot.select(name=\"first\")\n",
    "    second_old = dot.select(name=\"second\")\n",
    "    \n",
    "    pie = p.select(name=\"pie\")\n",
    "    \n",
    "    pl = lp.select(name=\"pl\")\n",
    "    nl = ln.select(name=\"nl\")\n",
    "    \n",
    "    # Removing the above obtained components from the renderer\n",
    "    if len(first_old)>0:\n",
    "        dot.renderers.remove(first_old[0])\n",
    "    if len(second_old)>0:\n",
    "        dot.renderers.remove(second_old[0])\n",
    "    if len(pie)>0:\n",
    "        p.renderers.remove(pie[0])\n",
    "    if len(pl)>0:\n",
    "        lp.renderers.remove(pl[0])\n",
    "    if len(nl)>0:\n",
    "        ln.renderers.remove(nl[0])\n",
    "    \n",
    "    # Setting a 'Valid' bit to indicate whether a tweets exist for a particular tweet topic\n",
    "    # 1 => tweets exist for the entered tweet topic, in the dataset\n",
    "    # 0 => tweets do not exist for the entered tweet topic, in the dataset\n",
    "    valid = 1\n",
    "    \n",
    "    # Read in the training data set\n",
    "    # Obtain the comments and the corresponding review sentiment for all the training reviews\n",
    "    tex = []\n",
    "    review = []\n",
    "    with open(\"data/train.csv\", encoding='latin1') as csvfile:\n",
    "        csv_read = csv.reader(csvfile, delimiter=',', quotechar='\"')\n",
    "        for row in csv_read:\n",
    "            tex.append(row[0])\n",
    "            review.append(row[1])            \n",
    "    \n",
    "    # Append the sentiment to the comments\n",
    "    train_data = np.column_stack([tex,review])\n",
    "    \n",
    "    # Calculate the number of positive and negative words in the tweets\n",
    "    negative_counts = word_counter(train_data, 'Negative')\n",
    "    positive_counts = word_counter(train_data, 'Positive')\n",
    "    \n",
    "    # Calculate the total number of tweets available for each class\n",
    "    positive_review_count = review_count('Positive',train_data)\n",
    "    negative_review_count = review_count('Negative',train_data)\n",
    "    \n",
    "    # Calculating the apriori probability of each class\n",
    "    # apriori <- (number of documents in a class) / (total number of documents)\n",
    "    positive_probability = positive_review_count / len(train_data)\n",
    "    negative_probability = negative_review_count / len(train_data)   \n",
    "    \n",
    "    # Load the test data from the Twitter dataset\n",
    "    test_data = []\n",
    "    dt_tm = []\n",
    "    with open(\"sentiment140/training.1600000.processed.noemoticon.csv\", encoding='latin1') as csvfile:\n",
    "        csv_read = csv.reader(csvfile, delimiter=',', quotechar='\"')\n",
    "        for row in csv_read:\n",
    "            # Obtain the tweet from the dataset, as the value in column 6\n",
    "            test_data.append(row[5])\n",
    "            # Obtain the date related to the tweet, from column 3 of the dataset\n",
    "            dt = row[2][4:11]+row[2][24:28]+\" \"+row[2][11:19].strip()\n",
    "            # Modify the date string to a datetime object\n",
    "            datetime_object = datetime.strptime(dt, '%b %d %Y %H:%M:%S')\n",
    "            # Store the datetime objects in a list\n",
    "            dt_tm.append(datetime_object.date())\n",
    "    \n",
    "    topic_tweets = []\n",
    "    dt_tm_sub = []\n",
    "\n",
    "    # Identify the tweets that contain the entered tweet topic\n",
    "    # Extract the obtained tweets and the corresponding dates and store them in 2 separate lists\n",
    "    for i in range(test_data.__len__()):\n",
    "        if (topic.lower() in test_data[i].lower()):\n",
    "            topic_tweets.append(test_data[i])\n",
    "            dt_tm_sub.append(dt_tm[i])\n",
    "\n",
    "    # Calculate the number of tweets that contain the entered tweet topic\n",
    "    tweets_cnt = len(topic_tweets)\n",
    "    \n",
    "    # Make the prediction of the tweet by using the probabilities and counts calculated above\n",
    "    predictions = [decide(r[5], predict, negative_counts, negative_probability, negative_review_count, positive_counts, positive_probability, positive_review_count) for r in topic_tweets]\n",
    "    \n",
    "    pos_count = 0\n",
    "    neg_count = 0\n",
    "    \n",
    "    neg_comments = []\n",
    "    pos_comments = []\n",
    "    \n",
    "    neg_dt = []\n",
    "    pos_dt = []\n",
    "    \n",
    "    # From the predictions made, count the number of positive and negative comments \n",
    "    # and separate the positive and negative comments into 2 separate lists\n",
    "    for i in range(len(predictions)):\n",
    "        if (predictions[i] == 'Negative'):\n",
    "            neg_count += 1\n",
    "            neg_comments.append(topic_tweets[i])\n",
    "            neg_dt.append(dt_tm_sub[i])\n",
    "        else:\n",
    "            pos_count += 1\n",
    "            pos_comments.append(topic_tweets[i])\n",
    "            pos_dt.append(dt_tm_sub[i])\n",
    "\n",
    "    # Define 2 data frames to store the dates for the line charts\n",
    "    dfn = pd.DataFrame(\n",
    "    {'Date': neg_dt\n",
    "    })\n",
    "    \n",
    "    dfp = pd.DataFrame(\n",
    "    {'Date': pos_dt\n",
    "    })\n",
    "\n",
    "    # Find the number of positive and negative counts for each date\n",
    "    dfn = dfn.groupby(['Date'], sort=True).size().reset_index(name='Count')\n",
    "    dfp = dfp.groupby(['Date'], sort=True).size().reset_index(name='Count')\n",
    "    \n",
    "    # Individually group the tweets predicted to be positive and negative tweets\n",
    "    update_text(neg_comments,pos_comments)\n",
    "    \n",
    "    print(\"Calculations completed for the topic\",topic,\"...\")\n",
    "    \n",
    "    # The charts need to be plotted only when the entered topic has any tweets, i.e., tweets_cnt > 0\n",
    "    # Else all the values should be 0 and no charts should be plotted\n",
    "    if(tweets_cnt > 0):\n",
    "        pos_pct = round(pos_count*100/tweets_cnt,2)\n",
    "        neg_pct = round(neg_count*100/tweets_cnt,2)\n",
    "    else:\n",
    "        pos_pct = 0\n",
    "        neg_pct = 0\n",
    "        valid = 0\n",
    "\n",
    "    percents = []\n",
    "    \n",
    "    p.title.text = \"Entered Tweet Topic: \" + topic\n",
    "    \n",
    "    # Define starts/ends for wedges from the percentages of a circle\n",
    "    percents.append(0)\n",
    "    percents.append(round(pos_pct/100,2))\n",
    "    percents.append(round((pos_pct+neg_pct)/100,2))\n",
    "    \n",
    "    starts = [p*2*pi for p in percents[:-1]]\n",
    "    ends = [p*2*pi for p in percents[1:]]\n",
    "    \n",
    "    # A color for each pie piece of the pie chart\n",
    "    # Red represents negative comments \n",
    "    # Green represents positive comments\n",
    "    colors = ['Green','Red']\n",
    "        \n",
    "    # If valid is 1, i.e., tweets pertaining to the entered topic exists, then draw all the charts in the application\n",
    "    if(valid == 1):\n",
    "        dot.segment(0, [\"Positive\", \"Negative\"], [pos_count,neg_count], [\"Positive\", \"Negative\"], name=\"first\", line_width=2, line_color=\"green\", )\n",
    "        dot.circle([pos_count,neg_count], [\"Positive\", \"Negative\"], name=\"second\", size=15, fill_color=\"orange\", line_color=\"green\", line_width=3, )\n",
    "        hover1 = HoverTool(tooltips = [('Positive Comments', str(pos_count)), ('Negative Comments', str(neg_count))], name=\"h1\")\n",
    "        dot.add_tools(hover1)\n",
    "        \n",
    "        p.wedge(x=0, y=0, radius=0.5, name=\"pie\", alpha=0.3, start_angle=starts, end_angle=ends, color=colors)\n",
    "\n",
    "        hover = HoverTool(tooltips = [('Positive Comments', str(pos_pct)+'%'), ('Negative Comments', str(neg_pct)+'%')], name=\"h\")\n",
    "        p.add_tools(hover)\n",
    "        \n",
    "        lp.line(dfp['Date'], dfp['Count'], line_width=2, color='Green', name=\"pl\")\n",
    "        ln.line(dfn['Date'], dfn['Count'], line_width=2, color='Red', name=\"nl\")\n",
    "        \n",
    "    # If valid is not 1, then do not draw any charts\n",
    "    # Just change the title of the chart to state that there are on related tweets available\n",
    "    else:\n",
    "        p.title.text = \"There are no tweets available for the topic \" + topic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Main module to plot the graphs and invoke all the other modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from bokeh.io import curdoc\n",
    "from bokeh.layouts import row, column, gridplot\n",
    "from bokeh.models import ColumnDataSource\n",
    "from bokeh.models.widgets import PreText, Select\n",
    "from bokeh.plotting import figure\n",
    "\n",
    "datan = PreText(text='', width=500)\n",
    "datap = PreText(text='', width=450)\n",
    "blank = PreText(text='', width=50)\n",
    "\n",
    "dot = figure(tools=\"\", toolbar_location=None, y_range=[\"Positive\", \"Negative\"], width=500, height=200)\n",
    "dot.xaxis.axis_label = 'Number of Comments'\n",
    "\n",
    "p = figure(x_range=(-1,1), y_range=(-1,1), tools=\"\", toolbar_location=None, width=500, height=400)\n",
    "p.axis.visible = False\n",
    "p.grid.visible = False\n",
    "\n",
    "lp = figure(x_axis_type=\"datetime\", title=\"Positive Comments\", tools=\"\", toolbar_location=None, width=500, height=250)\n",
    "lp.grid.grid_line_alpha = 0.3\n",
    "lp.xaxis.axis_label = 'Date'\n",
    "lp.yaxis.axis_label = 'Number of Comments'\n",
    "\n",
    "ln = figure(x_axis_type=\"datetime\", title=\"Negative Comments\", tools=\"\", toolbar_location=None, width=500, height=250)\n",
    "ln.grid.grid_line_alpha = 0.3\n",
    "ln.xaxis.axis_label = 'Date'\n",
    "ln.yaxis.axis_label = 'Number of Comments'\n",
    "\n",
    "def update_title(attrname, old, new):\n",
    "    topic = text.value.strip()\n",
    "    naive_bayes(topic)\n",
    "    \n",
    "text = TextInput(title=\"Enter a tweet topic: \", value='')\n",
    "text.on_change('value', update_title)\n",
    "\n",
    "inputs = widgetbox(text)\n",
    "\n",
    "widgets = row(column(lp,datap),blank,column(ln,datan))\n",
    "main = column(inputs,p,dot)\n",
    "layout = row(widgets,main)\n",
    "\n",
    "curdoc().add_root(layout)\n",
    "curdoc().title = \"Sentiment Analysis using Naive Bayes\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
